{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gépi Tanulás Klasszifikációs Feladatok Összefoglalója\n",
    "\n",
    "Ez a notebook összefoglalja a két klasszifikációs feladatot:\n",
    "1. Osztályozás szintetikus adatokon.\n",
    "2. Osztályozás a Wine adathalmazon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Szükséges Könyvtárak Importálása\n",
    "\n",
    "Először importáljuk az összes szükséges könyvtárat mindkét feladathoz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Mappák létrehozása az ábráknak (ha még nem léteznek)\n",
    "output_dir_part1 = \"part1_plots\"\n",
    "output_dir_part2 = \"part2_plots\"\n",
    "if not os.path.exists(output_dir_part1):\n",
    "    os.makedirs(output_dir_part1)\n",
    "if not os.path.exists(output_dir_part2):\n",
    "    os.makedirs(output_dir_part2)\n",
    "\n",
    "# Figyelmeztetések alapértelmezett kezelése\n",
    "warnings.filterwarnings(\"default\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Feladat: Osztályozás Szintetikus Adatokon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Adatgenerálás\n",
    "\n",
    "Létrehozunk egy mesterséges adathalmazt `make_blobs` segítségével. Az adathalmaz több dimenziós, de jól elkülönülő csoportokat (blobokat) tartalmaz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 241\n",
    "n_features = 11\n",
    "centers = 4\n",
    "cluster_std = 0.6\n",
    "random_state_part1 = 3650653441\n",
    "\n",
    "X_part1, y_part1 = make_blobs(n_samples=n_samples,\n",
    "                             n_features=n_features,\n",
    "                             centers=centers,\n",
    "                             cluster_std=cluster_std,\n",
    "                             random_state=random_state_part1)\n",
    "\n",
    "print(f\"1. Feladat - Generált adathalmaz alakja: X={X_part1.shape}, y={y_part1.shape}\")\n",
    "print(f\"1. Feladat - Osztályok eloszlása: {np.bincount(y_part1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Adat Vizualizációja (PCA)\n",
    "\n",
    "Mivel az adathalmaz több mint 2 dimenziós, Főkomponens Analízist (PCA) használunk a dimenziócsökkentésre, hogy 2D-ben ábrázolhassuk az osztályokat. PCA előtt standardizáljuk az adatokat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_pca_part1 = StandardScaler()\n",
    "X_scaled_part1 = scaler_pca_part1.fit_transform(X_part1)\n",
    "\n",
    "pca_part1 = PCA(n_components=2, random_state=random_state_part1)\n",
    "X_pca_part1 = pca_part1.fit_transform(X_scaled_part1)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "scatter_part1 = plt.scatter(X_pca_part1[:, 0], X_pca_part1[:, 1], c=y_part1, cmap='viridis', edgecolor='k', s=50)\n",
    "plt.title('1. Feladat - Generált adathalmaz (PCA után)')\n",
    "plt.xlabel('Első főkomponens')\n",
    "plt.ylabel('Második főkomponens')\n",
    "plt.legend(handles=scatter_part1.legend_elements()[0], labels=[f'Osztály {i}' for i in range(centers)])\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(output_dir_part1, 'generated_data_pca.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Adat Felosztása és Skálázása\n",
    "\n",
    "Az eredeti (nem PCA-zott) adatokat tanító és teszt halmazra osztjuk. A modellek (különösen az SVM és LogReg) tanítása előtt a tanító adatokon illesztett `StandardScaler`-rel skálázzuk a jellemzőket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_part1, X_test_part1, y_train_part1, y_test_part1 = train_test_split(\n",
    "    X_part1, y_part1, test_size=0.3, random_state=random_state_part1, stratify=y_part1\n",
    ")\n",
    "\n",
    "scaler_model_part1 = StandardScaler()\n",
    "X_train_scaled_part1 = scaler_model_part1.fit_transform(X_train_part1)\n",
    "X_test_scaled_part1 = scaler_model_part1.transform(X_test_part1)\n",
    "\n",
    "print(f\"1. Feladat - Tanító halmaz mérete: {X_train_scaled_part1.shape[0]}\")\n",
    "print(f\"1. Feladat - Teszt halmaz mérete: {X_test_scaled_part1.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Modellek Tanítása és Kiértékelése\n",
    "\n",
    "Definiáljuk, tanítjuk és kiértékeljük a Naiv Bayes, SVM és Logisztikus Regresszió modelleket. Mérjük a tanítási időt, pontosságot, és elkészítjük a riportot, valamint a konfúziós mátrixot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_part1 = {\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Support Vector Machine\": SVC(random_state=random_state_part1, probability=True),\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=random_state_part1, max_iter=1000)\n",
    "}\n",
    "\n",
    "results_part1 = {}\n",
    "training_times_part1 = {}\n",
    "\n",
    "print(\"\\n--- 1. Feladat: Modellek Kiértékelése ---\")\n",
    "\n",
    "for name, model in models_part1.items():\n",
    "    print(f\"\\n--- {name} ---\")\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train_scaled_part1, y_train_part1)\n",
    "    end_time = time.time()\n",
    "    training_times_part1[name] = end_time - start_time\n",
    "\n",
    "    y_pred_train_part1 = model.predict(X_train_scaled_part1)\n",
    "    y_pred_test_part1 = model.predict(X_test_scaled_part1)\n",
    "\n",
    "    accuracy_train_part1 = accuracy_score(y_train_part1, y_pred_train_part1)\n",
    "    accuracy_test_part1 = accuracy_score(y_test_part1, y_pred_test_part1)\n",
    "    report_test_part1 = classification_report(y_test_part1, y_pred_test_part1)\n",
    "    cm_test_part1 = confusion_matrix(y_test_part1, y_pred_test_part1)\n",
    "\n",
    "    results_part1[name] = {\n",
    "        \"model\": model,\n",
    "        \"accuracy_train\": accuracy_train_part1,\n",
    "        \"accuracy_test\": accuracy_test_part1,\n",
    "        \"report_test\": report_test_part1,\n",
    "        \"confusion_matrix_test\": cm_test_part1\n",
    "    }\n",
    "\n",
    "    print(f\"Tanítási idő: {training_times_part1[name]:.4f} másodperc\")\n",
    "    print(f\"Pontosság (Tanító halmaz): {accuracy_train_part1:.4f}\")\n",
    "    print(f\"Pontosság (Teszt halmaz): {accuracy_test_part1:.4f}\")\n",
    "    print(\"Osztályozási riport (Teszt halmaz):\")\n",
    "    print(report_test_part1)\n",
    "    print(\"Konfúziós mátrix (Teszt halmaz):\")\n",
    "\n",
    "    # Konfúziós mátrix ábrázolása\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(cm_test_part1, annot=True, fmt='d', cmap='Blues', xticklabels=range(centers), yticklabels=range(centers))\n",
    "    plt.xlabel('Jósolt osztály')\n",
    "    plt.ylabel('Valós osztály')\n",
    "    plt.title(f'{name} - Konfúziós Mátrix (Teszt)')\n",
    "    safe_name = name.replace(\" \", \"_\").lower()\n",
    "    plt.savefig(os.path.join(output_dir_part1, f'confusion_matrix_{safe_name}.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Eredmények Összefoglalása\n",
    "\n",
    "Táblázatos formában és ábraként is összefoglaljuk a modellek tanítási idejét és pontosságát."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 1. Feladat: Összehasonlítás ---\")\n",
    "print(f\"{'Modell':<25} {'Tanítási idő (s)':<20} {'Tanuló pontosság':<20} {'Teszt pontosság':<20}\")\n",
    "print(\"-\" * 85)\n",
    "table_data_part1 = []\n",
    "model_names_part1 = list(results_part1.keys())\n",
    "for name in model_names_part1:\n",
    "    metrics = results_part1[name]\n",
    "    print(f\"{name:<25} {training_times_part1[name]:<20.4f} {metrics['accuracy_train']:<20.4f} {metrics['accuracy_test']:<20.4f}\")\n",
    "    table_data_part1.append([f\"{training_times_part1[name]:.4f}\",\n",
    "                           f\"{metrics['accuracy_train']:.4f}\",\n",
    "                           f\"{metrics['accuracy_test']:.4f}\"])\n",
    "\n",
    "# Táblázat készítése ábraként\n",
    "fig, ax = plt.subplots(figsize=(10, max(1, len(model_names_part1) * 0.5)))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "columns = ['Tanítási idő (s)', 'Tanuló pontosság', 'Teszt pontosság']\n",
    "the_table = ax.table(cellText=table_data_part1,\n",
    "                     rowLabels=model_names_part1,\n",
    "                     colLabels=columns,\n",
    "                     loc='center',\n",
    "                     cellLoc='center')\n",
    "the_table.auto_set_font_size(False)\n",
    "the_table.set_fontsize(10)\n",
    "the_table.scale(1.2, 1.2)\n",
    "plt.title('1. Feladat - Modellek Összehasonlító Eredményei', y=1.1)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(output_dir_part1, 'summary_results_table.png'), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 SVM Hiperparaméter-Hangolás ('C')\n",
    "\n",
    "GridSearchCV segítségével megkeressük az SVM modell optimális `C` regularizációs paraméterét 5-szörös keresztvalidációval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 1. Feladat: Hiperparaméter-hangolás (SVM 'C') ---\")\n",
    "param_grid_svm_part1 = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "svm_cv_part1 = SVC(random_state=random_state_part1, probability=True)\n",
    "\n",
    "grid_search_part1 = GridSearchCV(svm_cv_part1, param_grid_svm_part1, cv=5, scoring='accuracy')\n",
    "grid_search_part1.fit(X_train_scaled_part1, y_train_part1)\n",
    "\n",
    "print(f\"Legjobb 'C' paraméter: {grid_search_part1.best_params_['C']}\")\n",
    "print(f\"Legjobb cross-validation pontosság: {grid_search_part1.best_score_:.4f}\")\n",
    "\n",
    "# Eredmények ábrázolása\n",
    "cv_results_part1 = grid_search_part1.cv_results_\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(param_grid_svm_part1['C'], cv_results_part1['mean_test_score'], marker='o')\n",
    "plt.xscale('log')\n",
    "plt.xlabel(\"'C' paraméter értéke\")\n",
    "plt.ylabel(\"Átlagos Cross-Validation Pontosság\")\n",
    "plt.title(\"1. Feladat - SVM Teljesítmény a 'C' paraméter függvényében\")\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(output_dir_part1, 'svm_c_parameter_tuning.png'))\n",
    "plt.show()\n",
    "\n",
    "# Legjobb modell kiértékelése\n",
    "best_svm_part1 = grid_search_part1.best_estimator_\n",
    "y_pred_svm_best_part1 = best_svm_part1.predict(X_test_scaled_part1)\n",
    "accuracy_svm_best_test_part1 = accuracy_score(y_test_part1, y_pred_svm_best_part1)\n",
    "print(f\"\\nLegjobb SVM modell pontossága a teszt halmazon: {accuracy_svm_best_test_part1:.4f}\")\n",
    "print(f\"  Legjobb SVM Támaszvektorok száma osztályonként: {best_svm_part1.n_support_}\")\n",
    "print(\"Osztályozási riport (Legjobb SVM, Teszt halmaz):\")\n",
    "print(classification_report(y_test_part1, y_pred_svm_best_part1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Logisztikus Regresszió Iterációk Hatása\n",
    "\n",
    "Megvizsgáljuk, hogyan befolyásolja a Logisztikus Regresszió `max_iter` paramétere a modell pontosságát."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 1. Feladat: Logisztikus Regresszió Iterációk Hatása ---\")\n",
    "iterations_part1 = [1, 2, 3, 4, 5, 10, 20, 50, 100, 200, 500, 1000]\n",
    "train_accuracies_lr_part1 = []\n",
    "test_accuracies_lr_part1 = []\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "for n_iter in iterations_part1:\n",
    "    lr_iter_part1 = LogisticRegression(random_state=random_state_part1, max_iter=n_iter, solver='lbfgs')\n",
    "    lr_iter_part1.fit(X_train_scaled_part1, y_train_part1)\n",
    "    train_acc = lr_iter_part1.score(X_train_scaled_part1, y_train_part1)\n",
    "    test_acc = lr_iter_part1.score(X_test_scaled_part1, y_test_part1)\n",
    "    train_accuracies_lr_part1.append(train_acc)\n",
    "    test_accuracies_lr_part1.append(test_acc)\n",
    "warnings.filterwarnings(\"default\", category=ConvergenceWarning)\n",
    "\n",
    "# Ábrázolás\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(iterations_part1, train_accuracies_lr_part1, marker='o', label='Tanuló pontosság')\n",
    "plt.plot(iterations_part1, test_accuracies_lr_part1, marker='x', linestyle='--', label='Teszt pontosság')\n",
    "plt.xlabel(\"Iterációk száma (max_iter)\")\n",
    "plt.ylabel(\"Pontosság\")\n",
    "plt.title(\"1. Feladat - Logisztikus Regresszió Pontossága az Iterációk Függvényében\")\n",
    "plt.xscale('log')\n",
    "plt.ylim(0.9, 1.02)\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.legend()\n",
    "plt.savefig(os.path.join(output_dir_part1, 'logistic_regression_accuracy_vs_iterations.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Döntési Határok Vizualizációja\n",
    "\n",
    "Kirajzoljuk a modellek döntési határait a 2D PCA-val redukált adatokon, hogy vizuálisan lássuk, hogyan osztályoznak."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- 1. Feladat: Döntési határok vizualizációja (PCA adatokon) ---\")\n",
    "\n",
    "# PCA adatok felosztása\n",
    "X_train_pca_part1, X_test_pca_part1, y_train_pca_part1, y_test_pca_part1 = train_test_split(\n",
    "    X_pca_part1, y_part1, test_size=0.3, random_state=random_state_part1, stratify=y_part1\n",
    ")\n",
    "\n",
    "# Modellek újratanítása a 2D PCA adatokon\n",
    "models_pca_part1 = {\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Support Vector Machine (Best C)\": best_svm_part1, # Hangolt SVM\n",
    "    \"Logistic Regression\": LogisticRegression(random_state=random_state_part1, max_iter=1000)\n",
    "}\n",
    "\n",
    "# Meshgrid létrehozása\n",
    "h = .02\n",
    "x_min, x_max = X_pca_part1[:, 0].min() - 1, X_pca_part1[:, 0].max() + 1\n",
    "y_min, y_max = X_pca_part1[:, 1].min() - 1, X_pca_part1[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                     np.arange(y_min, y_max, h))\n",
    "\n",
    "# Ábra létrehozása\n",
    "n_models_part1 = len(models_pca_part1)\n",
    "fig_db_part1, axes_db_part1 = plt.subplots(1, n_models_part1, figsize=(n_models_part1 * 6, 5))\n",
    "if n_models_part1 == 1:\n",
    "    axes_db_part1 = [axes_db_part1]\n",
    "\n",
    "all_handles_part1 = []\n",
    "all_labels_part1 = []\n",
    "class_labels_part1 = [f'Osztály {i}' for i in range(centers)]\n",
    "\n",
    "for idx, (name, model_pca) in enumerate(models_pca_part1.items()):\n",
    "    model_pca.fit(X_train_pca_part1, y_train_pca_part1)\n",
    "    Z = model_pca.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    ax = axes_db_part1[idx]\n",
    "    ax.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "    scatter_train = ax.scatter(X_train_pca_part1[:, 0], X_train_pca_part1[:, 1], c=y_train_pca_part1, cmap=plt.cm.coolwarm, s=20, edgecolors='k')\n",
    "    scatter_test = ax.scatter(X_test_pca_part1[:, 0], X_test_pca_part1[:, 1], c=y_test_pca_part1, cmap=plt.cm.coolwarm, s=50, edgecolors='grey', marker='^')\n",
    "\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(name)\n",
    "\n",
    "    if idx == 0:\n",
    "        handles_train, _ = scatter_train.legend_elements()\n",
    "        all_handles_part1.extend(handles_train)\n",
    "        all_labels_part1.extend(class_labels_part1)\n",
    "        all_handles_part1.append(scatter_test) # Handle for test points\n",
    "        all_labels_part1.append('Teszt pontok')\n",
    "\n",
    "fig_db_part1.legend(handles=all_handles_part1, labels=all_labels_part1, loc='center right', bbox_to_anchor=(1.1, 0.5))\n",
    "fig_db_part1.suptitle(\"1. Feladat - Döntési határok a 2D PCA adatokon\")\n",
    "plt.tight_layout(rect=[0, 0, 0.9, 1])\n",
    "plt.savefig(os.path.join(output_dir_part1, 'decision_boundaries_pca.png'), bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAz 1. részfeladat elemzése befejeződött.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feladat: Osztályozás a Wine Adathalmazon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Adat Betöltése\n",
    "\n",
    "Betöltjük a Wine adathalmazt az UCI Machine Learning Repository URL-jéről `pandas` segítségével, és megadjuk az oszlopneveket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_part2 = \"https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\"\n",
    "column_names_part2 = ['Class', 'Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash',\n",
    "                      'Magnesium', 'Total phenols', 'Flavanoids', 'Nonflavanoid phenols',\n",
    "                      'Proanthocyanins', 'Color intensity', 'Hue',\n",
    "                      'OD280/OD315 of diluted wines', 'Proline']\n",
    "\n",
    "try:\n",
    "    df_part2 = pd.read_csv(url_part2, header=None, names=column_names_part2)\n",
    "    print(\"2. Feladat - Wine adathalmaz sikeresen betöltve.\")\n",
    "    print(f\"Adathalmaz mérete: {df_part2.shape}\")\n",
    "    # print(\"Adathalmaz első 5 sora:\")\n",
    "    # display(df_part2.head()) # Use display in notebooks\n",
    "    # print(\"\\nInformáció az adathalmazról:\")\n",
    "    # df_part2.info()\n",
    "    print(\"\\nOsztályok eloszlása:\")\n",
    "    print(df_part2['Class'].value_counts())\n",
    "except Exception as e:\n",
    "    print(f\"Hiba történt az adatok letöltése közben: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Adat Vizualizációja (PCA)\n",
    "\n",
    "Az első feladathoz hasonlóan PCA-t alkalmazunk a Wine adathalmaz jellemzőire is a 2D vizualizációhoz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_part2' in locals(): # Csak akkor fut, ha az adatbetöltés sikeres volt\n",
    "    X_viz_part2 = df_part2.drop('Class', axis=1)\n",
    "    y_viz_part2 = df_part2['Class']\n",
    "\n",
    "    scaler_pca_part2 = StandardScaler()\n",
    "    X_viz_scaled_part2 = scaler_pca_part2.fit_transform(X_viz_part2)\n",
    "\n",
    "    pca_part2 = PCA(n_components=2, random_state=42)\n",
    "    X_pca_part2 = pca_part2.fit_transform(X_viz_scaled_part2)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter_part2 = plt.scatter(X_pca_part2[:, 0], X_pca_part2[:, 1], c=y_viz_part2, cmap='viridis', edgecolor='k', s=50)\n",
    "    plt.title('2. Feladat - Wine adathalmaz (PCA után)')\n",
    "    plt.xlabel('Első főkomponens')\n",
    "    plt.ylabel('Második főkomponens')\n",
    "    handles, labels = scatter_part2.legend_elements()\n",
    "    class_labels_part2 = [f'Osztály {i}' for i in sorted(y_viz_part2.unique())]\n",
    "    plt.legend(handles=handles, labels=class_labels_part2)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(output_dir_part2, 'wine_data_pca.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Adat Felosztása és Skálázása\n",
    "\n",
    "Felosztjuk a Wine adatokat tanító és teszt halmazra, majd skálázzuk őket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_part2' in locals():\n",
    "    X_part2 = df_part2.drop('Class', axis=1)\n",
    "    y_part2 = df_part2['Class']\n",
    "\n",
    "    X_train_part2, X_test_part2, y_train_part2, y_test_part2 = train_test_split(\n",
    "        X_part2, y_part2, test_size=0.3, random_state=42, stratify=y_part2\n",
    "    )\n",
    "\n",
    "    scaler_model_part2 = StandardScaler()\n",
    "    X_train_scaled_part2 = scaler_model_part2.fit_transform(X_train_part2)\n",
    "    X_test_scaled_part2 = scaler_model_part2.transform(X_test_part2)\n",
    "\n",
    "    print(f\"2. Feladat - Tanító halmaz mérete: {X_train_scaled_part2.shape[0]}\")\n",
    "    print(f\"2. Feladat - Teszt halmaz mérete: {X_test_scaled_part2.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Modellek Tanítása és Kiértékelése\n",
    "\n",
    "Tanítjuk és kiértékeljük a modelleket a Wine adathalmazon. Itt a k-NN modellt is hozzáadjuk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_part2' in locals():\n",
    "    models_part2 = {\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"Support Vector Machine\": SVC(random_state=42, probability=True),\n",
    "        \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=10000),\n",
    "        \"k-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5)\n",
    "    }\n",
    "\n",
    "    results_part2 = {}\n",
    "    training_times_part2 = {}\n",
    "\n",
    "    print(\"\\n--- 2. Feladat: Modellek Kiértékelése ---\")\n",
    "\n",
    "    for name, model in models_part2.items():\n",
    "        print(f\"\\n--- {name} ---\")\n",
    "        start_time = time.time()\n",
    "        model.fit(X_train_scaled_part2, y_train_part2)\n",
    "        end_time = time.time()\n",
    "        training_times_part2[name] = end_time - start_time\n",
    "\n",
    "        y_pred_train_part2 = model.predict(X_train_scaled_part2)\n",
    "        y_pred_test_part2 = model.predict(X_test_scaled_part2)\n",
    "\n",
    "        accuracy_train_part2 = accuracy_score(y_train_part2, y_pred_train_part2)\n",
    "        accuracy_test_part2 = accuracy_score(y_test_part2, y_pred_test_part2)\n",
    "        report_test_part2 = classification_report(y_test_part2, y_pred_test_part2)\n",
    "        cm_test_part2 = confusion_matrix(y_test_part2, y_pred_test_part2)\n",
    "\n",
    "        results_part2[name] = {\n",
    "            \"model\": model,\n",
    "            \"accuracy_train\": accuracy_train_part2,\n",
    "            \"accuracy_test\": accuracy_test_part2,\n",
    "            \"report_test\": report_test_part2,\n",
    "            \"confusion_matrix_test\": cm_test_part2\n",
    "        }\n",
    "\n",
    "        print(f\"Tanítási idő: {training_times_part2[name]:.4f} másodperc\")\n",
    "        print(f\"Pontosság (Tanító halmaz): {accuracy_train_part2:.4f}\")\n",
    "        print(f\"Pontosság (Teszt halmaz): {accuracy_test_part2:.4f}\")\n",
    "        print(\"Osztályozási riport (Teszt halmaz):\")\n",
    "        print(report_test_part2)\n",
    "        print(\"Konfúziós mátrix (Teszt halmaz):\")\n",
    "\n",
    "        # Konfúziós mátrix ábrázolása\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        class_labels_sorted_part2 = sorted(y_part2.unique())\n",
    "        sns.heatmap(cm_test_part2, annot=True, fmt='d', cmap='Blues',\n",
    "                    xticklabels=class_labels_sorted_part2, yticklabels=class_labels_sorted_part2)\n",
    "        plt.xlabel('Jósolt osztály')\n",
    "        plt.ylabel('Valós osztály')\n",
    "        plt.title(f'{name} - Konfúziós Mátrix (Teszt)')\n",
    "        safe_name = name.replace(\" \", \"_\").replace(\"-\", \"\").replace(\"(\", \"\").replace(\")\", \"\").lower()\n",
    "        plt.savefig(os.path.join(output_dir_part2, f'confusion_matrix_{safe_name}.png'))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Eredmények Összefoglalása\n",
    "\n",
    "Összefoglaljuk a Wine adathalmazon elért eredményeket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'results_part2' in locals():\n",
    "    print(\"\\n--- 2. Feladat: Összehasonlítás ---\")\n",
    "    print(f\"{'Modell':<25} {'Tanítási idő (s)':<20} {'Tanuló pontosság':<20} {'Teszt pontosság':<20}\")\n",
    "    print(\"-\" * 85)\n",
    "    table_data_part2 = []\n",
    "    model_names_part2 = list(results_part2.keys())\n",
    "    for name in model_names_part2:\n",
    "        metrics = results_part2[name]\n",
    "        print(f\"{name:<25} {training_times_part2[name]:<20.4f} {metrics['accuracy_train']:<20.4f} {metrics['accuracy_test']:<20.4f}\")\n",
    "        table_data_part2.append([f\"{training_times_part2[name]:.4f}\",\n",
    "                               f\"{metrics['accuracy_train']:.4f}\",\n",
    "                               f\"{metrics['accuracy_test']:.4f}\"])\n",
    "\n",
    "    # Táblázat készítése ábraként\n",
    "    fig_table, ax_table = plt.subplots(figsize=(10, max(2, len(model_names_part2) * 0.5)))\n",
    "    ax_table.axis('tight')\n",
    "    ax_table.axis('off')\n",
    "    columns_part2 = ['Tanítási idő (s)', 'Tanuló pontosság', 'Teszt pontosság']\n",
    "    the_table_part2 = ax_table.table(cellText=table_data_part2,\n",
    "                                     rowLabels=model_names_part2,\n",
    "                                     colLabels=columns_part2,\n",
    "                                     loc='center',\n",
    "                                     cellLoc='center')\n",
    "    the_table_part2.auto_set_font_size(False)\n",
    "    the_table_part2.set_fontsize(10)\n",
    "    the_table_part2.scale(1.2, 1.2)\n",
    "    plt.title('2. Feladat - Modellek Összehasonlító Eredményei (Wine)', y=1.1, fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir_part2, 'summary_results_table_part2.png'), bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Logisztikus Regresszió Iterációk Hatása\n",
    "\n",
    "Megvizsgáljuk a Logisztikus Regresszió konvergenciáját a Wine adathalmazon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_part2' in locals():\n",
    "    print(\"\\n--- 2. Feladat: Logisztikus Regresszió Iterációk Hatása ---\")\n",
    "    iterations_lr_part2 = [1, 5, 10, 20, 50, 100, 200, 500, 1000, 2000, 5000, 10000]\n",
    "    train_accuracies_lr_part2 = []\n",
    "    test_accuracies_lr_part2 = []\n",
    "\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "    for n_iter in iterations_lr_part2:\n",
    "        lr_iter_part2 = LogisticRegression(random_state=42, max_iter=n_iter, solver='lbfgs')\n",
    "        lr_iter_part2.fit(X_train_scaled_part2, y_train_part2)\n",
    "        train_acc = lr_iter_part2.score(X_train_scaled_part2, y_train_part2)\n",
    "        test_acc = lr_iter_part2.score(X_test_scaled_part2, y_test_part2)\n",
    "        train_accuracies_lr_part2.append(train_acc)\n",
    "        test_accuracies_lr_part2.append(test_acc)\n",
    "    warnings.filterwarnings(\"default\", category=ConvergenceWarning)\n",
    "\n",
    "    # Ábrázolás\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(iterations_lr_part2, train_accuracies_lr_part2, marker='o', label='Tanuló pontosság')\n",
    "    plt.plot(iterations_lr_part2, test_accuracies_lr_part2, marker='x', linestyle='--', label='Teszt pontosság')\n",
    "    plt.xlabel(\"Iterációk száma (max_iter)\")\n",
    "    plt.ylabel(\"Pontosság\")\n",
    "    plt.title(\"2. Feladat - Logisztikus Regresszió Pontossága az Iterációk Függvényében (Wine)\")\n",
    "    plt.xscale('log')\n",
    "    plt.ylim(0.9, 1.02)\n",
    "    plt.grid(True, which=\"both\", ls=\"--\")\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir_part2, 'logistic_regression_accuracy_vs_iterations_part2.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 SVM Hiperparaméter-Hangolás ('C' és 'gamma')\n",
    "\n",
    "GridSearchCV segítségével megkeressük az SVM modell optimális `C` és `gamma` paramétereit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_part2' in locals():\n",
    "    print(\"\\n--- 2. Feladat: Hiperparaméter-hangolás (SVM) ---\")\n",
    "    param_grid_svm_part2 = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'gamma': ['scale', 'auto', 0.1, 1],\n",
    "        'kernel': ['rbf']\n",
    "    }\n",
    "    svm_cv_part2 = SVC(probability=True)\n",
    "\n",
    "    grid_search_svm_part2 = GridSearchCV(estimator=svm_cv_part2,\n",
    "                                       param_grid=param_grid_svm_part2,\n",
    "                                       cv=5,\n",
    "                                       scoring='accuracy',\n",
    "                                       n_jobs=-1,\n",
    "                                       verbose=1)\n",
    "\n",
    "    print(\"GridSearchCV indítása SVM-re...\")\n",
    "    start_time_gs = time.time()\n",
    "    grid_search_svm_part2.fit(X_train_scaled_part2, y_train_part2)\n",
    "    end_time_gs = time.time()\n",
    "    print(f\"GridSearchCV befejezve. Idő: {end_time_gs - start_time_gs:.2f} másodperc\")\n",
    "\n",
    "    print(f\"\\nLegjobb paraméterek (SVM): {grid_search_svm_part2.best_params_}\")\n",
    "    print(f\"Legjobb keresztvalidációs pontosság (SVM): {grid_search_svm_part2.best_score_:.4f}\")\n",
    "\n",
    "    # Legjobb modell kiértékelése\n",
    "    best_svm_part2 = grid_search_svm_part2.best_estimator_\n",
    "    y_pred_svm_best_part2 = best_svm_part2.predict(X_test_scaled_part2)\n",
    "    accuracy_svm_best_test_part2 = accuracy_score(y_test_part2, y_pred_svm_best_part2)\n",
    "\n",
    "    print(f\"\\nLegjobb (hangolt) SVM modell pontossága a teszt halmazon: {accuracy_svm_best_test_part2:.4f}\")\n",
    "    print(f\"  Legjobb SVM Támaszvektorok száma osztályonként: {best_svm_part2.n_support_}\")\n",
    "    print(\"Osztályozási riport (Legjobb SVM, Teszt halmaz):\")\n",
    "    print(classification_report(y_test_part2, y_pred_svm_best_part2))\n",
    "\n",
    "    # Konfúziós mátrix a legjobb SVM modellhez\n",
    "    cm_svm_best_part2 = confusion_matrix(y_test_part2, y_pred_svm_best_part2)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    class_labels_sorted_part2 = sorted(y_part2.unique())\n",
    "    sns.heatmap(cm_svm_best_part2, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_labels_sorted_part2, yticklabels=class_labels_sorted_part2)\n",
    "    plt.xlabel('Jósolt osztály')\n",
    "    plt.ylabel('Valós osztály')\n",
    "    plt.title('Legjobb (hangolt) SVM - Konfúziós Mátrix (Teszt)')\n",
    "    plt.savefig(os.path.join(output_dir_part2, 'confusion_matrix_svm_best_tuned.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8 SVM Hangolás Vizualizációja (Heatmap)\n",
    "\n",
    "Heatmap segítségével ábrázoljuk, hogyan változott az SVM keresztvalidációs pontossága a `C` és `gamma` paraméterek különböző kombinációira."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'grid_search_svm_part2' in locals():\n",
    "    print(\"\\n--- 2. Feladat: SVM Hiperparaméter-hangolás Vizualizációja ---\")\n",
    "    results_df_part2 = pd.DataFrame(grid_search_svm_part2.cv_results_)\n",
    "    results_df_part2 = results_df_part2[['param_C', 'param_gamma', 'mean_test_score']]\n",
    "    results_df_part2['mean_test_score'] = results_df_part2['mean_test_score'].astype(float)\n",
    "\n",
    "    try:\n",
    "        # A pivot megpróbálja kezelni a 'scale', 'auto' stringeket is oszlopcímkeként\n",
    "        scores_part2 = results_df_part2.pivot(index='param_C', columns='param_gamma', values='mean_test_score')\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.heatmap(scores_part2, annot=True, fmt=\".4f\", cmap=\"viridis\")\n",
    "        plt.title('2. Feladat - SVM Keresztvalidációs Pontosság (Heatmap)')\n",
    "        plt.xlabel('Gamma paraméter')\n",
    "        plt.ylabel('C paraméter')\n",
    "        plt.savefig(os.path.join(output_dir_part2, 'svm_tuning_heatmap.png'))\n",
    "        plt.show()\n",
    "\n",
    "    except ValueError as ve:\n",
    "        print(f\"\\nHiba a heatmap készítésekor: {ve}\")\n",
    "        print(\"Lehetséges ok: A 'gamma' paraméter tartalmazott nem numerikus értékeket ('scale', 'auto').\")\n",
    "    except KeyError as ke:\n",
    "         print(f\"\\nHiba a heatmap készítésekor: Hiányzó oszlop - {ke}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9 Döntési Határok Vizualizációja\n",
    "\n",
    "Kirajzoljuk a modellek döntési határait a Wine adathalmaz PCA-val redukált változatán."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_part2' in locals() and 'grid_search_svm_part2' in locals():\n",
    "    print(\"\\n--- 2. Feladat: Döntési határok vizualizációja (PCA adatokon) ---\")\n",
    "\n",
    "    # PCA adatok felosztása\n",
    "    X_train_pca_part2, X_test_pca_part2, y_train_pca_part2, y_test_pca_part2 = train_test_split(\n",
    "        X_pca_part2, y_part2, test_size=0.3, random_state=42, stratify=y_part2\n",
    "    )\n",
    "\n",
    "    # Modellek PCA adatokhoz\n",
    "    models_pca_part2 = {\n",
    "        \"Naive Bayes\": GaussianNB(),\n",
    "        \"Best Tuned SVM\": grid_search_svm_part2.best_estimator_, # Hangolt SVM\n",
    "        \"Logistic Regression\": LogisticRegression(random_state=42, max_iter=10000)\n",
    "    }\n",
    "\n",
    "    # Meshgrid\n",
    "    h = .02\n",
    "    x_min, x_max = X_pca_part2[:, 0].min() - 1, X_pca_part2[:, 0].max() + 1\n",
    "    y_min, y_max = X_pca_part2[:, 1].min() - 1, X_pca_part2[:, 1].max() + 1\n",
    "    xx_part2, yy_part2 = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                                     np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Ábra\n",
    "    n_models_part2 = len(models_pca_part2)\n",
    "    fig_db_part2, axes_db_part2 = plt.subplots(1, n_models_part2, figsize=(n_models_part2 * 6, 5))\n",
    "    if n_models_part2 == 1:\n",
    "        axes_db_part2 = [axes_db_part2]\n",
    "\n",
    "    all_handles_part2 = []\n",
    "    all_labels_part2 = []\n",
    "    class_labels_pca_part2 = [f'Osztály {i}' for i in sorted(y_part2.unique())]\n",
    "\n",
    "    for idx, (name, model_pca) in enumerate(models_pca_part2.items()):\n",
    "        model_pca.fit(X_train_pca_part2, y_train_pca_part2)\n",
    "        Z_part2 = model_pca.predict(np.c_[xx_part2.ravel(), yy_part2.ravel()])\n",
    "        Z_part2 = Z_part2.reshape(xx_part2.shape)\n",
    "\n",
    "        ax = axes_db_part2[idx]\n",
    "        ax.contourf(xx_part2, yy_part2, Z_part2, cmap=plt.cm.viridis, alpha=0.6)\n",
    "        scatter_train_pca = ax.scatter(X_train_pca_part2[:, 0], X_train_pca_part2[:, 1], c=y_train_pca_part2,\n",
    "                                      cmap=plt.cm.viridis, edgecolor='k', s=20)\n",
    "        scatter_test_pca = ax.scatter(X_test_pca_part2[:, 0], X_test_pca_part2[:, 1], c=y_test_pca_part2,\n",
    "                                     cmap=plt.cm.viridis, edgecolor='k', marker='^', s=30)\n",
    "\n",
    "        ax.set_xlim(xx_part2.min(), xx_part2.max())\n",
    "        ax.set_ylim(yy_part2.min(), yy_part2.max())\n",
    "        ax.set_xticks(())\n",
    "        ax.set_yticks(())\n",
    "        ax.set_title(name)\n",
    "\n",
    "        if idx == 0:\n",
    "            handles_train, _ = scatter_train_pca.legend_elements()\n",
    "            all_handles_part2.extend(handles_train)\n",
    "            all_labels_part2.extend(class_labels_pca_part2)\n",
    "            all_handles_part2.append(scatter_test_pca) # Handle for test points\n",
    "            all_labels_part2.append('Teszt pontok')\n",
    "\n",
    "    fig_db_part2.legend(handles=all_handles_part2, labels=all_labels_part2, loc='lower center', ncol=len(all_labels_part2), bbox_to_anchor=(0.5, -0.05))\n",
    "    fig_db_part2.suptitle('2. Feladat - Modellek Döntési Határai (PCA-redukált Wine Adatokon)', fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.savefig(os.path.join(output_dir_part2, 'decision_boundaries_pca_part2.png'), bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nAz 2. részfeladat elemzése befejeződött.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.x.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}